
Introduction
TAMS best practices, mainly introducing image generation tasks, resource uploading, model acquisition, and other operations, to help you efficiently use TAMS and meet your business needs

What's Stage
We have divided the task into a workflow with stages as granularity, so that the application can obtain output images by combining different stages according to its own scenarios. Based on the processing flow, we have defined basic types for stages to identify what program should be used to process the images.

Introduction to Basic Stage Types
INPUT_INITIALIZE
Input initialization stage, used to input necessary parameters for generating images.

Seed: Initialize the canvas with a random seed.
ImageResourceId: Initialize the canvas with an image.
Count: Number of output images.
DIFFUSION
Diffusion stage, used to generate basic images based on the basic parameters (width, height, steps, prmopts) and the selection of Base Model, LoRA, Controlnet, etc.

IMAGE_TO_ADETAILER
ADETAILER (AFTER DETAILER) is mainly used to save time for quick redrawing and repairing of faces or hands.

IMAGE_TO_UPSCALER
Upscale the image for super-resolution scaling.

IMAGE_TO_INPAINT
Redraw specific parts of the image.

Use a diagram to describe the processing flow of a group of stages using one image

Intro To Billing
This article mainly introduces the billing methods and pricing for image generation capabilities. Other unpaid capabilities are currently in public testing phase and can be used for free.

Price of publication
$0.003/credit
Gift	Workspace API(SD WebUI like)	Workflow API (ComfyUI like)	AI Tools	4080/4090	Free website membership account	Support the use of self-selected Models / AI Tools list
First Login	1k Credits for free	✅	✅	✅	4080-Equivalent	❌	❌
Purchase 10k Credits	/	✅	✅	✅	4080-Equivalent	❌	❌
Purchase 100k Credits	5k Credits	✅	✅	✅	4080-Equivalent	✅	❌
Purchase 1,000k Credits	100k Credits	✅	✅	✅	4090-Equivalent	✅	✅
Purchase 10,000k Credits	2,500k Credits	✅	✅	✅	4090-Equivalent	✅	✅
Advanced customization plan	Contact Us	✅	✅	✅	4090-Equivalent	✅	✅
Credit
A credit is a unit of currency expended when generating images with TAMS or after submitting a request to our API. Credit usage scales according to the compute required to complete your request.

Calculation Formula for Credits：
The four factors that currently affect Credits are:

WIDTH, HEIGHT
STEPS
COUNT (The number of generated images)
MODEL_FACTOR (based on whether SD or SDXL is being used)
info
The coefficients for the current SDXL model are temporarily discounted and consistent with SD, with all coefficients set to 1. For the FLUX model, the coefficients are set to 2.

notice
The ADETAILER Stage traverses through Args to perform calculations. It uses the ad_steps from the arg for computation. If the ad_use_steps parameter is used, it inherits the steps from DIFFUSION and includes them in the calculation.

Calculation is done separately for each stage, but the later stages inherit certain parameters (WIDTH, HEIGHT, STEPS) from the previous stages for calculation.

For example, if there are four stages:

INPUT_INITIALIZE: COUNT: 1
DIFFUSION: STEPS: 20, Credits: 0.8
UPSCALER: STEPS: 30, WIDTH: 1920, HEIGHT: 1080, Credits: 2.4
ADETAILER: inherits WIDTH and HEIGHT from UPSCALER, and STEPS from DIFFUSION, Credits: 1.6
Total cumulative consumption: 4.8
ADETAILER/INPAINT STEPS inheritance rule:

If there is a DIFFUSION stage, it inherits the STEPS from DIFFUSION.
If there is no DIFFUSION stage, it uses the STEPS parameter.
ADETAILER/INPAINT WIDTH and HEIGHT inheritance rule:

If it is not the first stage of generating the image (excluding INPUT_INITIALIZE), it inherits the WIDTH and HEIGHT generated by the previous stage.
If it is the first stage of generating the image (excluding INPUT_INITIALIZE), it uses the WIDTH and HEIGHT from DIFFUSION parameter.
INPUT_INITIALIZE
Initialization COUNT,MODEL_FACTOR

DIFFUSION:
MODEL_FACTOR * COUNT * (CEIL( STEPS / 5 ) / 5)

Some examples:

STEPS	Credits
2	0.2
8	0.4
20	0.8
25	1
30	1.2
35	1.4
40	1.6
50	2
60	2.4
ADETAILER/INPAINT/UPSCALER
MODEL_FACTOR * COUNT * (CEIL( STEPS / 5 ) / 5) * CEIL( WIDTH * HEIGHT / 1024 / 1024 * 2) / 2

For FLUX.1 model UPSCALER, MODEL_FACTOR * COUNT * (CEIL( STEPS / 5 ) / 5) * CEIL( WIDTH * HEIGHT / 1024 / 1024 * 3) / 2

Some examples:

STEPS	WIDTH	HEIGHT	Credits
30	1280	768	2
30	1920	1080	3.2
30	2560	1440	5
60	1280	768	3.2
60	1920	1080	5.6
60	2560	1440	10.4
VIDEO DIFFUSION
Video diffusion credit calculation is based on several factors including the model used, video parameters, and generation mode.

The formula for calculating video diffusion credits is:

(Total Frames + 1) Model Coefficient Discount Factor * 1.25

Model Coefficients
Model	Coefficient (Text-to-Video)	Coefficient (Image-to-Video)
MOCHI_1_10B	0.45	0.45
COGVIDEOX_2B	0.19	0.19
COGVIDEOX_5B	0.23	0.23
COGVIDEOX1_5_5B	0.93	0.93
PYRAMID_FLOW_MINIFLUX (640×384)	0.09	0.09
PYRAMID_FLOW_MINIFLUX (1280×768)	0.29	0.29
LTX_VIDEO_2B	0.05	0.05
HUNYUANVIDEO	0.45	0.42
HUNYUANVIDEO_FAST	0.30	0.30
COSMOS_1_7B	0.73	1.0
SKYREELS_V1	0.91	0.91
WAN_2_1	0.72	0.72
Other models	1.0	1.0
Fast Generation Mode Discounts
When using FAST generation mode, the following discount factors are applied:

Model	Discount Factor
HUNYUANVIDEO	0.5
LTX_VIDEO_2B	0.6
COGVIDEOX1_5_5B	0.5
WAN_2_1	0.67
Other models	1.0 (no discount)
Example Calculations
For a video with 30 frames using HUNYUANVIDEO in text-to-video mode with normal generation:

(30 + 1) 0.45 1.0 * 1.25 = 17.44 credits

For a video with 30 frames using HUNYUANVIDEO in text-to-video mode with FAST generation:

(30 + 1) 0.45 0.5 * 1.25 = 8.72 credits

For a video with 24 frames using COGVIDEOX_2B:

(24 + 1) 0.19 1.0 * 1.25 = 5.94 credits

info
Video credit calculations are rounded to 2 decimal places.


txt2img
2img API
Basic minimum workflow
Request Body:

{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "seed": -1,
        "count": 2
      }
    },
    {
      "type": "DIFFUSION",
      "diffusion": {
        "width": 512,
        "height": 512,
        "prompts": [
          {
            "text": "1girl"
          }
        ],
        "sampler": "DPM++ 2M Karras",
        "sdVae": "Automatic",
        "steps": 15,
        "sd_model": "600423083519508503",
        "clip_skip": 2,
        "cfg_scale": 7
      }
    }
  ]
}

Add Adetailer
Request Body:

{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "seed": -1,
        "count": 2
      }
    },
    {
      "type": "DIFFUSION",
      "diffusion": {
        "width": 512,
        "height": 512,
        "prompts": [
          {
            "text": "1girl"
          }
        ],
        "sampler": "DPM++ 2M Karras",
        "sdVae": "Automatic",
        "steps": 15,
        "sd_model": "600423083519508503",
        "clip_skip": 2,
        "cfg_scale": 7
      }
    },
    {
      "type": "IMAGE_TO_ADETAILER",
      "image_to_adetailer": {
        "args": [
          {
            "ad_model": "face_yolov8s.pt",
            "ad_confidence": 0.7,
            "ad_dilate_erode": 4,
            "ad_denoising_strength": 0.4,
            "ad_inpaint_only_masked": true,
            "ad_inpaint_only_masked_padding": 32
          }
        ]
      }
    }
  ]
}

Add Upscaler
Request Body:

{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "seed": -1, // RANDOM SEED
        "count": 2 // GENERATE COUNT
      }
    },
    {
      "type": "DIFFUSION",
      "diffusion": {
        "width": 512,
        "height": 512,
        "prompts": [
          {
            "text": "1girl"
          }
        ],
        "sampler": "DPM++ 2M Karras",
        "sdVae": "Automatic",
        "steps": 15,
        "sd_model": "600423083519508503", //checkpoint, the id ref from website
        "clip_skip": 2,
        "cfg_scale": 7
      }
    },
    {
      "type": "IMAGE_TO_UPSCALER",
      "image_to_upscaler": {
        "hr_upscaler": "Latent",
        "hr_scale": 2,
        "hr_second_pass_steps": 10,
        "denoising_strength": 0.3
      }
    }
  ]
}


img2img
2img API
Basic minimum workflow
Call Get Resource Upload Address, and upload the image to the returned address, get the resource id

请求参数

{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "image_resource_id": "f204c24a-52dc-4cf4-930a-9b8f73969414",
        "count": 2
      }
    },
    {
      "type": "DIFFUSION",
      "diffusion": {
        "width": 512,
        "height": 512,
        "prompts": [
          {
            "text": "1girl"
          }
        ],
        "sampler": "DPM++ 2M Karras",
        "sdVae": "Automatic",
        "steps": 15,
        "sd_model": "600423083519508503",
        "clip_skip": 2,
        "cfg_scale": 7
      }
    }
  ]
}

Adetailer
images after detail directly without Diffusion
caution
Do not perform the Diffusion operation, therefore inputInitialize.count can only be 1

Although not using Diffusion, image_to_adetailer still needs parameters with the original image diffusion

{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "image_resource_id": "f204c24a-52dc-4cf4-930a-9b8f73969414",
        "count": 1
      }
    },
    {
      "type": "IMAGE_TO_ADETAILER",
      "image_to_adetailer": {
        "args": [
          {
            "ad_model": "face_yolov8s.pt",
            "ad_confidence": 0.7,
            "ad_dilate_erode": 4,
            "ad_denoising_strength": 0.4,
            "ad_inpaint_only_masked": true,
            "ad_inpaint_only_masked_padding": 32
          }
        ],
        "diffusion": {
          "width": 512,
          "height": 512,
          "prompts": [
            {
              "text": "1girl"
            }
          ],
          "sampler": "DPM++ 2M Karras",
          "sdVae": "Automatic",
          "steps": 15,
          "sd_model": "600423083519508503",
          "clip_skip": 2,
          "cfg_scale": 7
        }
      }
    }
  ]
}

Image To Adetailer
{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "image_resource_id": "f204c24a-52dc-4cf4-930a-9b8f73969414",
        "count": 2
      }
    },
    {
      "type": "DIFFUSION",
      "diffusion": {
        "width": 512,
        "height": 512,
        "prompts": [
          {
            "text": "1girl"
          }
        ],
        "sampler": "DPM++ 2M Karras",
        "sdVae": "Automatic",
        "steps": 15,
        "sd_model": "600423083519508503",
        "clip_skip": 2,
        "cfg_scale": 7
      }
    },
    {
      "type": "IMAGE_TO_ADETAILER",
      "image_to_adetailer": {
        "args": [
          {
            "ad_model": "face_yolov8s.pt",
            "ad_confidence": 0.7,
            "ad_dilate_erode": 4,
            "ad_denoising_strength": 0.4,
            "ad_inpaint_only_masked": true,
            "ad_inpaint_only_masked_padding": 32
          }
        ]
      }
    }
  ]
}

Upscaler
Upscale the image directly without Diffusion
caution
Do not perform the Diffusion operation, therefore inputInitialize.count can only be 1

Although not using Diffusion, image_to_upscaler still requires parameters with the original image diffusion

{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "image_resource_id": "f204c24a-52dc-4cf4-930a-9b8f73969414",
        "count": 1
      }
    },
    {
      "type": "IMAGE_TO_UPSCALER",
      "image_to_upscaler": {
        "hr_upscaler": "Latent",
        "hr_scale": 2,
        "hr_second_pass_steps": 10,
        "denoising_strength": 0.3,
        "diffusion": {
          "width": 512,
          "height": 512,
          "prompts": [
            {
              "text": "1girl"
            }
          ],
          "sampler": "DPM++ 2M Karras",
          "sdVae": "Automatic",
          "steps": 15,
          "sd_model": "600423083519508503",
          "clip_skip": 2,
          "cfg_scale": 7
        }
      }
    }
  ]
}

Image to Upscaler
caution
When using Image to Upscaler, image_to_upscaler.hr_upscaler prohibits the use of late, as late only takes effect during the Diffusion phase of txt2img

{
  "request_id": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "image_resource_id": "f204c24a-52dc-4cf4-930a-9b8f73969414",
        "count": 2
      }
    },
    {
      "type": "DIFFUSION",
      "diffusion": {
        "width": 512,
        "height": 512,
        "prompts": [
          {
            "text": "1girl"
          }
        ],
        "sampler": "DPM++ 2M Karras",
        "sdVae": "Automatic",
        "steps": 15,
        "sd_model": "600423083519508503", //checkpoint
        "clip_skip": 2,
        "cfg_scale": 7
      }
    },
    {
      "type": "IMAGE_TO_UPSCALER",
      "image_to_upscaler": {
        "hr_upscaler": "4x-UltraSharp",
        "hr_scale": 2,
        "hr_second_pass_steps": 10,
        "denoising_strength": 0.3
      }
    }
  ]
}

Inpaint
Perform inpainting on an image directly without diffusion
First, let's generate an image to be processed.
Request Body:

{
  "requestId": "unique_key",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": { "seed": "933011881", "count": 1 }
    },
    {
      "type": "DIFFUSION",
      "diffusion": {
        "width": 512,
        "height": 768,
        "prompts": [
          { "text": "wide shot" },
          { "text": "(depth of field)" },
          { "text": "global illumination" },
          { "text": "soft shadows" },
          { "text": "grand scene" },
          { "text": "backlight" },
          { "text": "lens flare" },
          { "text": "((colorful refraction))" },
          { "text": "((cinematic lighting))" },
          { "text": "in the market" },
          { "text": "looking outside" },
          { "text": "with butterfly" },
          { "text": "1girl with lightblue long hair and blue aqua eyes" },
          { "text": "hair flowers" },
          { "text": "hime cut" },
          { "text": "sunlight" },
          { "text": "blurry background" },
          { "text": "blurry" },
          { "text": "White Dress" },
          { "text": "full of flowers" },
          { "text": "light bule butterfly" },
          { "text": " from side" },
          { "text": "floating hair" }
        ],
        "negativePrompts": [
          { "text": " (worst quality" },
          { "text": " low quality:1.4)" },
          { "text": " negative_hand Negative Embedding" },
          { "text": "verybadimagenegative_v1.3" },
          {}
        ],
        "sdModel": "681693017352010007",
        "sdVae": "None",
        "sampler": "DPM++ 3M SDE Karras",
        "steps": 25,
        "cfgScale": 5,
        "clipSkip": 2,
        "denoisingStrength": 0.4,
        "lora": {}
      }
    },
    {
      "type": "IMAGE_TO_UPSCALER",
      "imageToUpscaler": {
        "hrUpscaler": "4x-AnimeSharp",
        "hrResizeX": 1536,
        "hrResizeY": 2304,
        "hrSecondPassSteps": 10,
        "denoisingStrength": 0.4
      }
    }
  ]
}

tip
Please remember to replace the 'requestId' in the request with your own unique ID.

We have obtained an image 

Then we need a mask image
You can use some image editing tools to draw a black background image and paint the parts that need to be redrawn in white.

tip
Remember that the mask image format should be JPEG, and the resolution of the mask image should be exactly the same as that of the original image.

Let's do a partial redraw of the face and get a masked image that has the face region selected. 

Perform inpainting
Our goal is to redraw the face with a crying expression, red pupils, and eyes. The structure of inpainting is:

{
  "imageToInpaint": {
    "resizeMode": "JUST_RESIZE",
    "maskImageResourceId": "48203af7-6b07-4f1c-8506-f3f545613653",
    "maskBlur": 4,
    "inpaintingFill": "ORIGINAL",
    "inpaintFullRes": true,
    "inpaintFullResPadding": 32,
    "diffusion": {
      "width": 512,
      "height": 768,
      "prompts": [
        {
          "text": "crying"
        },
        {
          "text": " (red eyes:1.5)"
        }
      ],
      "negativePrompts": [
        {
          "text": " (worst quality, low quality:1.4)"
        },
        {
          "text": " negative_hand Negative Embedding"
        },
        {
          "text": "verybadimagenegative_v1.3"
        },
        {}
      ],
      "sdModel": "681693017352010007",
      "sdVae": "None",
      "sampler": "DPM++ 3M SDE Karras",
      "steps": 25,
      "cfgScale": 5,
      "clipSkip": 2,
      "denoisingStrength": 0.4,
      "lora": {}
    }
  }
}

Complete request example:

{
  "requestId": "685205102316761513",
  "stages": [
    {
      "type": "INPUT_INITIALIZE",
      "inputInitialize": {
        "seed": "-1",
        "imageResourceId": "67f8de0b-4949-4f88-abb4-cf57b16459da",
        "count": 1
      }
    },
    {
      "type": "IMAGE_TO_INPAINT",
      "imageToInpaint": {
        "resizeMode": "JUST_RESIZE",
        "maskImageResourceId": "48203af7-6b07-4f1c-8506-f3f545613653",
        "maskBlur": 4,
        "inpaintingFill": "ORIGINAL",
        "inpaintFullRes": true,
        "inpaintFullResPadding": 32,
        "diffusion": {
          "width": 512,
          "height": 768,
          "prompts": [{ "text": "crying" }, { "text": " (red eyes:1.5)" }],
          "negativePrompts": [
            { "text": " (worst quality" },
            { "text": " low quality:1.4)" },
            { "text": " negative_hand Negative Embedding" },
            { "text": "verybadimagenegative_v1.3" },
            {}
          ],
          "sdModel": "681693017352010007",
          "sdVae": "None",
          "sampler": "DPM++ 3M SDE Karras",
          "steps": 25,
          "cfgScale": 5,
          "clipSkip": 2,
          "denoisingStrength": 0.4,
          "lora": {}
        }
      }
    }
  ]
}

The final resulting image is as follows:
Lora
How to Get the Model ID for Lora

The structure related to Lora is as follows:

{
    "lora": {
        "items": [
            {
                "loraModel": "661652545330040294",
                "weight": 1.1
            }
        ]
    }
}

Put fields into the request Example:

{
    "requestId": "unique_key",
    "stages": [
        {
            "type": "INPUT_INITIALIZE",
            "inputInitialize": {
                "seed": "-1",
                "count": 1
            }
        },
        {
            "type": "DIFFUSION",
            "diffusion": {
                "width": 512,
                "height": 768,
                "prompts": [
                    {
                        "text": "1girl"
                    }
                ],
                "negativePrompts": [
                    {
                        "text": "EasyNegative"
                    }
                ],
                "sdModel": "613045163490732233",
                "sdVae": "vae-ft-mse-840000-ema-pruned.ckpt",
                "sampler": "Euler a",
                "steps": 25,
                "cfgScale": 7,
                "clipSkip": 2,
                "etaNoiseSeedDelta": 31337,
                "lora": {
                    "items": [
                        {
                            "loraModel": "661652545330040294",
                            "weight": 1.1
                        }
                    ]
                }
            }
        }
    ]
}


Workflow Template
The interfaces related to workflow templates allow users to generate diagrams using a predefined series of templates, requiring only simple modifications to a few parameters within the template.

Usage in ComfyUI
Usage in ComfyUI https://github.com/Tensor-Art/ComfyUI_TENSOR_ART



Get Workflow Template
Request Parameter Example: Replace the following parameters in the URL path.

template_id: 676018193025756628

Response (Including all fields that need to be modified) :

{
  "templateId": "676018193025756628",
  "name": "二次元转真实",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "25",
        "fieldName": "image",
        "fieldValue": ""
      },
      {
        "nodeId": "27",
        "fieldName": "text",
        "fieldValue": "1 girl"
      }
    ]
  }
}

Check Workflow Template Parameters
This interface first retrieves the workflow template, then replaces the fields corresponding to the request parameters in the obtained template (specifically, replacing the field_value in the node_id corresponding to field with field_name). After the replacement is completed, it checks if the parameters are valid. If they are valid, it returns the estimated credits based on the parameters.

Error Request Example 1(Some fields are missing in the parameters.):

{
  "template_id": "676018193025756628",
  "fields": {
    "field_attrs": [
      {
        "node_id": "27",
        "field_name": "text",
        "field_value": "1 girl, amber_eyes"
      }
    ]
  }
}

Response:

{
  "code": 2,
  "message": "can't find [nodeId:fieldName] 25:image in fields parameter"
}

Error Request Example 2: During the processing of this request, the image of node_25 in the obtained template will be set to null. Since this action is invalid, it will return false along with the error reason.

{
  "templateId": "676018193025756628",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "25",
        "fieldName": "image",
        "fieldValue": null
      },
      {
        "nodeId": "27",
        "fieldName": "text",
        "fieldValue": "1 girl"
      }
    ]
  }
}

Response:

{
  "code": 3,
  "message": "Params Valid",
  "details": [
    {
      "@type": "type.googleapis.com/tams_api.ArgumentError",
      "field": "workflow",
      "message": "node id: 25\nclass type: LoadImage\nimage: 字段必填\n"
    }
  ]
}

Correct Request Example:

{
  "templateId": "676018193025756628",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "25",
        "fieldName": "image",
        "fieldValue": "f29036b4-ff7b-4394-8c26-aabc1bdae008"
      },
      {
        "nodeId": "27",
        "fieldName": "text",
        "fieldValue": "1 girl"
      }
    ]
  }
}

Response (estimated credits are 1):

{
  "valid": true,
  "credits": 1
}

Create Workflow Template Job
This interface also retrieves the workflow template, then replaces the fields and checks the parameters. After the checking is completed, it creates a new job to generate the diagram. (fieldValue is the media_resource_id obtained after uploading the image)

Request Example:

{
  "request_id": "cc05d4e1a98f8a1438ea6ebcce77a8d5",
  "templateId": "676018193025756628",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "25",
        "fieldName": "image",
        "fieldValue": "f29036b4-ff7b-4394-8c26-aabc1bdae008"
      },
      {
        "nodeId": "27",
        "fieldName": "text",
        "fieldValue": "1 girl"
      }
    ]
  }
}

request_id is an md5 string generated based on the current timestamp. You can use the following JavaScript script or script in other languages to generate it:

const crypto = require('crypto')
const request_id = crypto
  .createHash('md5')
  .update('' + Date.now())
  .digest('hex')
console.log(request_id)

Response (You can query the diagram generation status using the returned jobId. The status of the newly created job is CREATED):

{
  "job": {
    "id": "709385162603889157",
    "status": "CREATED"
  }
}

Previous
workflow
Next

workflow
Using workflows to generate
request body：

{
  "requestId": "678571482378412436",
  "params": {
    "10": {
      "classType": "LoraLoader",
      "inputs": {
        "clip": ["4", 1],
        "lora_name": "648628718430054626",
        "model": ["4", 0],
        "strength_clip": 1,
        "strength_model": 1
      }
    },
    "14": {
      "classType": "LoraLoader",
      "inputs": {
        "clip": ["10", 1],
        "lora_name": "631627137633337321",
        "model": ["10", 0],
        "strength_clip": 1,
        "strength_model": 0.6
      }
    },
    "16": {
      "classType": "LatentUpscale",
      "inputs": {
        "crop": "disabled",
        "height": 1536,
        "samples": ["3", 0],
        "upscale_method": "nearest-exact",
        "width": 1024
      }
    },
    "17": {
      "classType": "KSampler",
      "inputs": {
        "cfg": 8,
        "denoise": 0.3,
        "latent_image": ["16", 0],
        "model": ["4", 0],
        "negative": ["7", 0],
        "positive": ["6", 0],
        "sampler_name": "dpmpp_2m_sde",
        "scheduler": "karras",
        "seed": 12345,
        "steps": 30
      }
    },
    "18": {
      "classType": "VAEDecode",
      "inputs": {
        "samples": ["17", 0],
        "vae": ["4", 2]
      }
    },
    "3": {
      "classType": "KSampler",
      "inputs": {
        "cfg": 7,
        "denoise": 1,
        "latent_image": ["5", 0],
        "model": ["14", 0],
        "negative": ["7", 0],
        "positive": ["6", 0],
        "sampler_name": "dpmpp_2m_sde",
        "scheduler": "karras",
        "seed": 12345,
        "steps": 26
      }
    },
    "4": {
      "classType": "CheckpointLoaderSimple",
      "inputs": {
        "ckpt_name": "664602165660323756"
      }
    },
    "5": {
      "classType": "EmptyLatentImage",
      "inputs": {
        "batch_size": 1,
        "height": 1536,
        "width": 1024
      }
    },
    "6": {
      "classType": "CLIPTextEncode",
      "inputs": {
        "clip": ["14", 1],
        "text": " (masterpiece, best quality:1.2),  layla, layla, masterpiece, bestquality, 8k, cg"
      }
    },
    "7": {
      "classType": "CLIPTextEncode",
      "inputs": {
        "clip": ["14", 1],
        "text": "sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), ((2girl)), (deformed fingers:1.2), (long fingers:1.2),(bad-artist-anime), bad-artist, bad hand, extra legs."
      }
    },
    "9": {
      "classType": "SaveImage",
      "inputs": {
        "filename_prefix": "TensorArt",
        "images": ["18", 0]
      }
    }
  }
}


Return result：

{
  "job": {
    "id": "683082404926062625",
    "status": "CREATED"
  }
}

Get workflow result
Return result：

{
    "job": {
        "id": "683082404926062625",
        "status": "RUNNING",
        "credits": 2.4,
        "runningInfo": {
            "workflowFinishItem": {
                "status": "SUCCESS",
                "nodes": {
                    "16": {
                        "id": "16",
                        "status": "SUCCESS"
                    },
                    "17": {
                        "id": "17",
                        "status": "SUCCESS",
                        "process": 1
                    },
                    "18": {
                        "id": "18",
                        "status": "SUCCESS"
                    },
                    "3": {
                        "id": "3",
                        "status": "SUCCESS",
                        "process": 1
                    },
                    "9": {
                        "id": "9",
                        "status": "SUCCESS",
                        "outputUi": {
                            "images": [
                                {
                                    "filename": "http://tams-tusi-resource-sig.oss-cn-shanghai.aliyuncs.com/resource-upload%2Fshort-term%2F2024-01-15%2F94e1cbc2-871e-44b6-b0ca-79a4f78b38b4.png?Expires=1705318301&OSSAccessKeyId=LTAI5tA9wgpRFMZ23PwaJcL4&Signature=h2Z4ITwDiefBX6uHVjSZVXOEgIc%3D",
                                    "type": "output",
                                    "height": 1536,
                                    "width": 1024,
                                    "format": "png",
                                    "imageResourceId": "94e1cbc2-871e-44b6-b0ca-79a4f78b38b4"
                                },
                                {
                                    "filename": "http://tams-tusi-resource-sig.oss-cn-shanghai.aliyuncs.com/resource-upload%2Fshort-term%2F2024-01-15%2F053dc46e-c432-4f55-9f0d-5c44ce264714.png?Expires=1705318301&OSSAccessKeyId=LTAI5tA9wgpRFMZ23PwaJcL4&Signature=PN5YD%2F6pMAFC3lYoa1pEvDikzUk%3D",
                                    "type": "output",
                                    "height": 1536,
                                    "width": 1024,
                                    "format": "png",
                                    "imageResourceId": "053dc46e-c432-4f55-9f0d-5c44ce264714"
                                }
                            ]
                        }
                    }
                }
            }
        }
    }
}


Previous
Controlnet
Next


Go to the TensorArt website



Go to the details page of the desired model 

Find the corresponding ID in the address bar For example: https://tensor.art/models/619225630271212879

Model ID

619225630271212879




APIcontrolnet-detectv1/controlnet/detect
v1/controlnet/detect
POST
https://｛endpoint}/v1/controlnet/detect
controlnet-detect

Request
application/json
Body
required
controlnetModule
string
required
the name of the controlnet preprocessor to use for detection. eg: openpose

resourceId
string
required
resource id of the image to detect in the controlnet.

Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
result
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/controlnet/detect"

payload = json.dumps({
  "controlnetModule": "string",
  "resourceId": "string"
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "controlnetModule": "string",
  "resourceId": "string"
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!

Previous
Introduction
Next
v1/img2prompt

APIimg2promptv1/img2prompt
v1/img2prompt
POST
https://｛endpoint}/v1/img2prompt
img2prompt

Request
application/json
Body
required
resourceId
string
required
The resource ID of the image to be tagged.

tagger
string
If natural language generation is needed, provide tagger=llm.

Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
prompts
string[]
The generated prompts for the image.

curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/img2prompt"

payload = json.dumps({
  "resourceId": "string",
  "tagger": "string"
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "resourceId": "string",
  "tagger": "string"
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!

APIjobsv1/jobs
v1/jobs
POST
https://｛endpoint}/v1/jobs
create diffusion job

Request
application/json
Body
required
requestId
string
required
ensure request idempotence, should be unique

stages
object[]
required
notifyUrl
string
Responses
200
400
default
OK

application/json
Schema
Example (from schema)
Schema
job
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/jobs"

payload = json.dumps({
  "requestId": "string",
  "stages": [
    {
      "type": "DEFAULT",
      "inputInitialize": {
        "seed": "0",
        "imageResourceId": "string",
        "count": "1"
      },
      "diffusion": {
        "width": "512",
        "height": "512",
        "prompts": {},
        "negativePrompts": {},
        "sdModel": {},
        "sdVae": {},
        "sampler": "string",
        "steps": "0",
        "cfgScale": 0,
        "clipSkip": 0,
        "denoisingStrength": 0,
        "etaNoiseSeedDelta": 0,
        "controlnet": {
          "args": [
            {
              "inputImageResourceId": "string",
              "maskResourceId": "string",
              "preprocessor": {},
              "model": {},
              "weight": 0,
              "resizeMode": "DEFAULT",
              "guidance": 0,
              "guidanceStart": 0,
              "guidanceEnd": 0,
              "controlMode": "DEFAULT",
              "pixelPerfect": True,
              "preprocessorParams": {}
            }
          ]
        },
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "animateDiff": {
          "args": [
            {
              "videoLength": 0,
              "fps": 0,
              "motionLora": {
                "items": [
                  {
                    "loraModel": {},
                    "weight": 0,
                    "blockWeight": "string",
                    "loraAccessKey": "string"
                  }
                ]
              }
            }
          ]
        },
        "embedding": {
          "items": [
            {
              "model": {},
              "weight": 0,
              "embeddingAccessKey": "string"
            }
          ]
        },
        "v1Clip": True,
        "modelAccessKey": "string",
        "scheduleName": "string",
        "enableElla": True,
        "enablePix2pix": True,
        "useHunyuanDit": True,
        "layerDiffusion": {
          "enable": True,
          "weight": 0
        },
        "clipEncoderName": "string"
      },
      "imageToUpscaler": {
        "hrUpscaler": {},
        "hrResizeX": 0,
        "hrResizeY": 0,
        "hrScale": {},
        "hrSecondPassSteps": {},
        "denoisingStrength": {},
        "diffusion": {}
      },
      "imageToAdetailer": {
        "args": [
          {
            "adModel": "string",
            "adPrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adNegativePrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adConfidence": 0,
            "adDilateErode": "4",
            "adMaskMergeInvert": "None",
            "adDenoisingStrength": 0,
            "adInpaintOnlyMasked": "true",
            "adInpaintOnlyMaskedPadding": 0,
            "adUseInpaintWidthHeight": "false",
            "adInpaintWidth": "512",
            "adInpaintHeight": "512",
            "adUseSteps": "false",
            "adSteps": "20",
            "adUseCfgScale": "false",
            "adCfgScale": 0,
            "lora": {
              "items": [
                {
                  "loraModel": {},
                  "weight": 0,
                  "blockWeight": "string",
                  "loraAccessKey": "string"
                }
              ]
            },
            "adUseCheckpoint": True,
            "adCheckpoint": "string",
            "adUseSampler": True,
            "adUseNoiseMultiplier": True,
            "adNoiseMultiplier": 0,
            "adUseClipSkip": True,
            "adClipSkip": 0,
            "adSampler": "string"
          }
        ],
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": True,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": True,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": True,
          "enablePix2pix": True,
          "useHunyuanDit": True,
          "layerDiffusion": {
            "enable": True,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "imageToInpaint": {
        "resizeMode": "DEFAULT",
        "maskImageResourceId": "string",
        "maskBlur": 0,
        "inpaintingFill": "DEFAULT",
        "inpaintFullRes": True,
        "inpaintFullResPadding": 0,
        "inpaintMaskInvert": 0,
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": True,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": True,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": True,
          "enablePix2pix": True,
          "useHunyuanDit": True,
          "layerDiffusion": {
            "enable": True,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "videoDiffusion": {
        "sdModel": {},
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "generationMode": "DEFAULT",
        "width": 0,
        "height": 0,
        "fps": 0,
        "totalFrames": 0,
        "prompts": {},
        "negativePrompts": {},
        "modelAccessKey": "string",
        "controlnet": {
          "args": [
            {
              "inputVideoResourceId": "string",
              "preprocessor": {}
            }
          ]
        },
        "inp": {
          "args": [
            {
              "startImageResourceId": "string",
              "endImageResourceId": "string"
            }
          ]
        }
      }
    }
  ],
  "notifyUrl": "string"
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "requestId": "string",
  "stages": [
    {
      "type": "DEFAULT",
      "inputInitialize": {
        "seed": "0",
        "imageResourceId": "string",
        "count": "1"
      },
      "diffusion": {
        "width": "512",
        "height": "512",
        "prompts": {},
        "negativePrompts": {},
        "sdModel": {},
        "sdVae": {},
        "sampler": "string",
        "steps": "0",
        "cfgScale": 0,
        "clipSkip": 0,
        "denoisingStrength": 0,
        "etaNoiseSeedDelta": 0,
        "controlnet": {
          "args": [
            {
              "inputImageResourceId": "string",
              "maskResourceId": "string",
              "preprocessor": {},
              "model": {},
              "weight": 0,
              "resizeMode": "DEFAULT",
              "guidance": 0,
              "guidanceStart": 0,
              "guidanceEnd": 0,
              "controlMode": "DEFAULT",
              "pixelPerfect": true,
              "preprocessorParams": {}
            }
          ]
        },
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "animateDiff": {
          "args": [
            {
              "videoLength": 0,
              "fps": 0,
              "motionLora": {
                "items": [
                  {
                    "loraModel": {},
                    "weight": 0,
                    "blockWeight": "string",
                    "loraAccessKey": "string"
                  }
                ]
              }
            }
          ]
        },
        "embedding": {
          "items": [
            {
              "model": {},
              "weight": 0,
              "embeddingAccessKey": "string"
            }
          ]
        },
        "v1Clip": true,
        "modelAccessKey": "string",
        "scheduleName": "string",
        "enableElla": true,
        "enablePix2pix": true,
        "useHunyuanDit": true,
        "layerDiffusion": {
          "enable": true,
          "weight": 0
        },
        "clipEncoderName": "string"
      },
      "imageToUpscaler": {
        "hrUpscaler": {},
        "hrResizeX": 0,
        "hrResizeY": 0,
        "hrScale": {},
        "hrSecondPassSteps": {},
        "denoisingStrength": {},
        "diffusion": {}
      },
      "imageToAdetailer": {
        "args": [
          {
            "adModel": "string",
            "adPrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adNegativePrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adConfidence": 0,
            "adDilateErode": "4",
            "adMaskMergeInvert": "None",
            "adDenoisingStrength": 0,
            "adInpaintOnlyMasked": "true",
            "adInpaintOnlyMaskedPadding": 0,
            "adUseInpaintWidthHeight": "false",
            "adInpaintWidth": "512",
            "adInpaintHeight": "512",
            "adUseSteps": "false",
            "adSteps": "20",
            "adUseCfgScale": "false",
            "adCfgScale": 0,
            "lora": {
              "items": [
                {
                  "loraModel": {},
                  "weight": 0,
                  "blockWeight": "string",
                  "loraAccessKey": "string"
                }
              ]
            },
            "adUseCheckpoint": true,
            "adCheckpoint": "string",
            "adUseSampler": true,
            "adUseNoiseMultiplier": true,
            "adNoiseMultiplier": 0,
            "adUseClipSkip": true,
            "adClipSkip": 0,
            "adSampler": "string"
          }
        ],
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": true,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": true,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": true,
          "enablePix2pix": true,
          "useHunyuanDit": true,
          "layerDiffusion": {
            "enable": true,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "imageToInpaint": {
        "resizeMode": "DEFAULT",
        "maskImageResourceId": "string",
        "maskBlur": 0,
        "inpaintingFill": "DEFAULT",
        "inpaintFullRes": true,
        "inpaintFullResPadding": 0,
        "inpaintMaskInvert": 0,
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": true,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": true,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": true,
          "enablePix2pix": true,
          "useHunyuanDit": true,
          "layerDiffusion": {
            "enable": true,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "videoDiffusion": {
        "sdModel": {},
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "generationMode": "DEFAULT",
        "width": 0,
        "height": 0,
        "fps": 0,
        "totalFrames": 0,
        "prompts": {},
        "negativePrompts": {},
        "modelAccessKey": "string",
        "controlnet": {
          "args": [
            {
              "inputVideoResourceId": "string",
              "preprocessor": {}
            }
          ]
        },
        "inp": {
          "args": [
            {
              "startImageResourceId": "string",
              "endImageResourceId": "string"
            }
          ]
        }
      }
    }
  ],
  "notifyUrl": "string"
}
Send API Request
Response
Clear
APIjobsv1/jobs/credits
v1/jobs/credits
POST
https://｛endpoint}/v1/jobs/credits
check job

Request
application/json
Body
required
stages
object[]
required
Responses
200
400
default
OK

application/json
Schema
Example (from schema)
Schema
credits
double
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/jobs/credits"

payload = json.dumps({
  "stages": [
    {
      "type": "DEFAULT",
      "inputInitialize": {
        "seed": "0",
        "imageResourceId": "string",
        "count": "1"
      },
      "diffusion": {
        "width": "512",
        "height": "512",
        "prompts": {},
        "negativePrompts": {},
        "sdModel": {},
        "sdVae": {},
        "sampler": "string",
        "steps": "0",
        "cfgScale": 0,
        "clipSkip": 0,
        "denoisingStrength": 0,
        "etaNoiseSeedDelta": 0,
        "controlnet": {
          "args": [
            {
              "inputImageResourceId": "string",
              "maskResourceId": "string",
              "preprocessor": {},
              "model": {},
              "weight": 0,
              "resizeMode": "DEFAULT",
              "guidance": 0,
              "guidanceStart": 0,
              "guidanceEnd": 0,
              "controlMode": "DEFAULT",
              "pixelPerfect": True,
              "preprocessorParams": {}
            }
          ]
        },
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "animateDiff": {
          "args": [
            {
              "videoLength": 0,
              "fps": 0,
              "motionLora": {
                "items": [
                  {
                    "loraModel": {},
                    "weight": 0,
                    "blockWeight": "string",
                    "loraAccessKey": "string"
                  }
                ]
              }
            }
          ]
        },
        "embedding": {
          "items": [
            {
              "model": {},
              "weight": 0,
              "embeddingAccessKey": "string"
            }
          ]
        },
        "v1Clip": True,
        "modelAccessKey": "string",
        "scheduleName": "string",
        "enableElla": True,
        "enablePix2pix": True,
        "useHunyuanDit": True,
        "layerDiffusion": {
          "enable": True,
          "weight": 0
        },
        "clipEncoderName": "string"
      },
      "imageToUpscaler": {
        "hrUpscaler": {},
        "hrResizeX": 0,
        "hrResizeY": 0,
        "hrScale": {},
        "hrSecondPassSteps": {},
        "denoisingStrength": {},
        "diffusion": {}
      },
      "imageToAdetailer": {
        "args": [
          {
            "adModel": "string",
            "adPrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adNegativePrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adConfidence": 0,
            "adDilateErode": "4",
            "adMaskMergeInvert": "None",
            "adDenoisingStrength": 0,
            "adInpaintOnlyMasked": "true",
            "adInpaintOnlyMaskedPadding": 0,
            "adUseInpaintWidthHeight": "false",
            "adInpaintWidth": "512",
            "adInpaintHeight": "512",
            "adUseSteps": "false",
            "adSteps": "20",
            "adUseCfgScale": "false",
            "adCfgScale": 0,
            "lora": {
              "items": [
                {
                  "loraModel": {},
                  "weight": 0,
                  "blockWeight": "string",
                  "loraAccessKey": "string"
                }
              ]
            },
            "adUseCheckpoint": True,
            "adCheckpoint": "string",
            "adUseSampler": True,
            "adUseNoiseMultiplier": True,
            "adNoiseMultiplier": 0,
            "adUseClipSkip": True,
            "adClipSkip": 0,
            "adSampler": "string"
          }
        ],
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": True,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": True,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": True,
          "enablePix2pix": True,
          "useHunyuanDit": True,
          "layerDiffusion": {
            "enable": True,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "imageToInpaint": {
        "resizeMode": "DEFAULT",
        "maskImageResourceId": "string",
        "maskBlur": 0,
        "inpaintingFill": "DEFAULT",
        "inpaintFullRes": True,
        "inpaintFullResPadding": 0,
        "inpaintMaskInvert": 0,
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": True,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": True,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": True,
          "enablePix2pix": True,
          "useHunyuanDit": True,
          "layerDiffusion": {
            "enable": True,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "videoDiffusion": {
        "sdModel": {},
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "generationMode": "DEFAULT",
        "width": 0,
        "height": 0,
        "fps": 0,
        "totalFrames": 0,
        "prompts": {},
        "negativePrompts": {},
        "modelAccessKey": "string",
        "controlnet": {
          "args": [
            {
              "inputVideoResourceId": "string",
              "preprocessor": {}
            }
          ]
        },
        "inp": {
          "args": [
            {
              "startImageResourceId": "string",
              "endImageResourceId": "string"
            }
          ]
        }
      }
    }
  ]
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "stages": [
    {
      "type": "DEFAULT",
      "inputInitialize": {
        "seed": "0",
        "imageResourceId": "string",
        "count": "1"
      },
      "diffusion": {
        "width": "512",
        "height": "512",
        "prompts": {},
        "negativePrompts": {},
        "sdModel": {},
        "sdVae": {},
        "sampler": "string",
        "steps": "0",
        "cfgScale": 0,
        "clipSkip": 0,
        "denoisingStrength": 0,
        "etaNoiseSeedDelta": 0,
        "controlnet": {
          "args": [
            {
              "inputImageResourceId": "string",
              "maskResourceId": "string",
              "preprocessor": {},
              "model": {},
              "weight": 0,
              "resizeMode": "DEFAULT",
              "guidance": 0,
              "guidanceStart": 0,
              "guidanceEnd": 0,
              "controlMode": "DEFAULT",
              "pixelPerfect": true,
              "preprocessorParams": {}
            }
          ]
        },
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "animateDiff": {
          "args": [
            {
              "videoLength": 0,
              "fps": 0,
              "motionLora": {
                "items": [
                  {
                    "loraModel": {},
                    "weight": 0,
                    "blockWeight": "string",
                    "loraAccessKey": "string"
                  }
                ]
              }
            }
          ]
        },
        "embedding": {
          "items": [
            {
              "model": {},
              "weight": 0,
              "embeddingAccessKey": "string"
            }
          ]
        },
        "v1Clip": true,
        "modelAccessKey": "string",
        "scheduleName": "string",
        "enableElla": true,
        "enablePix2pix": true,
        "useHunyuanDit": true,
        "layerDiffusion": {
          "enable": true,
          "weight": 0
        },
        "clipEncoderName": "string"
      },
      "imageToUpscaler": {
        "hrUpscaler": {},
        "hrResizeX": 0,
        "hrResizeY": 0,
        "hrScale": {},
        "hrSecondPassSteps": {},
        "denoisingStrength": {},
        "diffusion": {}
      },
      "imageToAdetailer": {
        "args": [
          {
            "adModel": "string",
            "adPrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adNegativePrompt": [
              {
                "text": "string",
                "weight": 0
              }
            ],
            "adConfidence": 0,
            "adDilateErode": "4",
            "adMaskMergeInvert": "None",
            "adDenoisingStrength": 0,
            "adInpaintOnlyMasked": "true",
            "adInpaintOnlyMaskedPadding": 0,
            "adUseInpaintWidthHeight": "false",
            "adInpaintWidth": "512",
            "adInpaintHeight": "512",
            "adUseSteps": "false",
            "adSteps": "20",
            "adUseCfgScale": "false",
            "adCfgScale": 0,
            "lora": {
              "items": [
                {
                  "loraModel": {},
                  "weight": 0,
                  "blockWeight": "string",
                  "loraAccessKey": "string"
                }
              ]
            },
            "adUseCheckpoint": true,
            "adCheckpoint": "string",
            "adUseSampler": true,
            "adUseNoiseMultiplier": true,
            "adNoiseMultiplier": 0,
            "adUseClipSkip": true,
            "adClipSkip": 0,
            "adSampler": "string"
          }
        ],
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": true,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": true,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": true,
          "enablePix2pix": true,
          "useHunyuanDit": true,
          "layerDiffusion": {
            "enable": true,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "imageToInpaint": {
        "resizeMode": "DEFAULT",
        "maskImageResourceId": "string",
        "maskBlur": 0,
        "inpaintingFill": "DEFAULT",
        "inpaintFullRes": true,
        "inpaintFullResPadding": 0,
        "inpaintMaskInvert": 0,
        "diffusion": {
          "width": "512",
          "height": "512",
          "prompts": {},
          "negativePrompts": {},
          "sdModel": {},
          "sdVae": {},
          "sampler": "string",
          "steps": "0",
          "cfgScale": 0,
          "clipSkip": 0,
          "denoisingStrength": 0,
          "etaNoiseSeedDelta": 0,
          "controlnet": {
            "args": [
              {
                "inputImageResourceId": "string",
                "maskResourceId": "string",
                "preprocessor": {},
                "model": {},
                "weight": 0,
                "resizeMode": "DEFAULT",
                "guidance": 0,
                "guidanceStart": 0,
                "guidanceEnd": 0,
                "controlMode": "DEFAULT",
                "pixelPerfect": true,
                "preprocessorParams": {}
              }
            ]
          },
          "lora": {
            "items": [
              {
                "loraModel": {},
                "weight": 0,
                "blockWeight": "string",
                "loraAccessKey": "string"
              }
            ]
          },
          "animateDiff": {
            "args": [
              {
                "videoLength": 0,
                "fps": 0,
                "motionLora": {
                  "items": [
                    {
                      "loraModel": {},
                      "weight": 0,
                      "blockWeight": "string",
                      "loraAccessKey": "string"
                    }
                  ]
                }
              }
            ]
          },
          "embedding": {
            "items": [
              {
                "model": {},
                "weight": 0,
                "embeddingAccessKey": "string"
              }
            ]
          },
          "v1Clip": true,
          "modelAccessKey": "string",
          "scheduleName": "string",
          "enableElla": true,
          "enablePix2pix": true,
          "useHunyuanDit": true,
          "layerDiffusion": {
            "enable": true,
            "weight": 0
          },
          "clipEncoderName": "string"
        }
      },
      "videoDiffusion": {
        "sdModel": {},
        "lora": {
          "items": [
            {
              "loraModel": {},
              "weight": 0,
              "blockWeight": "string",
              "loraAccessKey": "string"
            }
          ]
        },
        "generationMode": "DEFAULT",
        "width": 0,
        "height": 0,
        "fps": 0,
        "totalFrames": 0,
        "prompts": {},
        "negativePrompts": {},
        "modelAccessKey": "string",
        "controlnet": {
          "args": [
            {
              "inputVideoResourceId": "string",
              "preprocessor": {}
            }
          ]
        },
        "inp": {
          "args": [
            {
              "startImageResourceId": "string",
              "endImageResourceId": "string"
            }
          ]
        }
      }
    }
  ]
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!

Previous
v1/jobs
Next
Click the Send API Request button above and see the response here!
APIjobsv1/jobs/workflow
v1/jobs/workflow
POST
https://｛endpoint}/v1/jobs/workflow
create workflow job

Request
application/json
Body
required
requestId
string
params
object
runningNotifyUrl
string
Responses
200
400
default
OK

application/json
Schema
Example (from schema)
Schema
job
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/jobs/workflow"

payload = json.dumps({
  "requestId": "string",
  "params": {},
  "runningNotifyUrl": "string"
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "requestId": "string",
  "params": {},
  "runningNotifyUrl": "string"
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!

APIjobsv1/jobs/workflow/params/check
v1/jobs/workflow/params/check
POST
https://｛endpoint}/v1/jobs/workflow/params/check
check workflow request params

Request
application/json
Body
required
params
object
Responses
200
400
default
OK

application/json
Schema
Example (from schema)
Schema
valid
boolean
credits
float
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/jobs/workflow/params/check"

payload = json.dumps({
  "params": {}
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "params": {}
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!

APIjobsv1/jobs
v1/jobs
GET
https://｛endpoint}/v1/jobs/:jobId
get job

Request
Path Parameters
jobId
uint64
required
Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
job
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests

url = "https://｛endpoint}/v1/jobs/:jobId"

payload={}
headers = {
  'Accept': 'application/json'
}

response = requests.request("GET", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Parameters
jobId — pathrequired
jobId
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!
APIworkflowv1/jobs/workflow/template
v1/jobs/workflow/template
POST
https://｛endpoint}/v1/jobs/workflow/template
create workflow job from template

Request
application/json
Body
required
requestId
string
templateId
uint64
fields
object
Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
job
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/jobs/workflow/template"

payload = json.dumps({
  "requestId": "string",
  "templateId": "string",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "string",
        "fieldName": "string",
        "fieldValue": {}
      }
    ]
  }
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "requestId": "string",
  "templateId": "string",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "string",
        "fieldName": "string",
        "fieldValue": {}
      }
    ]
  }
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!
APIworkflowv1/workflows/template/check
v1/workflows/template/check
POST
https://｛endpoint}/v1/workflows/template/check
check workflow template params

Request
application/json
Body
required
templateId
uint64
fields
object
Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
valid
boolean
credits
float
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/workflows/template/check"

payload = json.dumps({
  "templateId": "string",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "string",
        "fieldName": "string",
        "fieldValue": {}
      }
    ]
  }
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "templateId": "string",
  "fields": {
    "fieldAttrs": [
      {
        "nodeId": "string",
        "fieldName": "string",
        "fieldValue": {}
      }
    ]
  }
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!
APIworkflowv1/workflows/:template_id
v1/workflows/:template_id
GET
https://｛endpoint}/v1/workflows/:templateId
get workflow template info

Request
Path Parameters
templateId
uint64
required
Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
templateId
uint64
name
string
workflow template name

fields
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests

url = "https://｛endpoint}/v1/workflows/:templateId"

payload={}
headers = {
  'Accept': 'application/json'
}

response = requests.request("GET", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Parameters
templateId — pathrequired
templateId
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!

APImodelsv1/models/:model_id
v1/models/:model_id
GET
https://｛endpoint}/v1/models/:modelId
cancel job

Request
Path Parameters
modelId
uint64
required
Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
model
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests

url = "https://｛endpoint}/v1/models/:modelId"

payload={}
headers = {
  'Accept': 'application/json'
}

response = requests.request("GET", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Parameters
modelId — pathrequired
modelId
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!
APIresourcev1/resource/image
v1/resource/image
POST
https://｛endpoint}/v1/resource/image
create resource image

Request
application/json
Body
required
expireSec
int64
Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
resourceId
string
putUrl
string
headers
object
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/resource/image"

payload = json.dumps({
  "expireSec": "string"
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "expireSec": "string"
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!
APIresourcev1/resource/image/sts
v1/resource/image/sts
POST
https://｛endpoint}/v1/resource/image/sts
create resource image sts

Request
application/json
Body
required
expireSec
int64
Responses
200
404
default
OK

application/json
Schema
Example (from schema)
Schema
resourceId
string
accessId
string
signature
string
host
string
expire
string
callback
string
filePath
string
policy
string
securityToken
string
curl
python
go
nodejs
ruby
csharp
php
java
powershell
REQUESTS
HTTP.CLIENT
import requests
import json

url = "https://｛endpoint}/v1/resource/image/sts"

payload = json.dumps({
  "expireSec": "string"
})
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)

print(response.text)



Request
Collapse all
Base URL
https://｛endpoint}
Body
 required
{
  "expireSec": "string"
}
Send API Request
Response
Clear
Click the Send API Request button above and see the response here!

